# -*- coding: utf-8 -*-
"""StocksRNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c5WoTgXYhd0Xn18V0oTVR7WSer7rqt-W

# Stocks RNN Predictor
"""

# Getting Data - Only in Colab
# !kaggle datasets download -d borismarjanovic/price-volume-data-for-all-us-stocks-etfs
# !unzip /content/price-volume-data-for-all-us-stocks-etfs.zip

import numpy as np
import matplotlib.pyplot as plt
import os
import torch
import torch.nn as nn
import pandas as pd

np.random.seed(7)

data_path = "/content/Stocks"

def get_all_files(data_path=data_path):
    """
    Given a path to the stocks data, this function will return the file
    locations of companies consisting of at least 100 lines of previous stocks
    data.
    """
    all_files = []

    for file in os.listdir(data_path)[:100]:
        f = open(data_path + '/' + file)
        if len(f.readlines()) > 100:
            all_files.append(data_path + '/' + file)
        f.close()

    return all_files

all_files = get_all_files(data_path)

n = len(all_files)

all_files = np.array(all_files, dtype=str)
np.random.shuffle(all_files)

training_files = all_files[:int(n*0.6)]
validation_files = all_files[int(n*0.6):int(n*0.8)]
test_files = all_files[int(n*0.8):]

training_files

def transform_data(file, K, augment=False):
    """
    Given a file and a K value, this function returns X and T.
    Each row of X contains K x 4 values where each row represents
    the open, high, low, and close prices for the previous K days.
    Each row of T represents the closing price of the K+1 day.
    If augment is true, the function also adds the reverse of the data.
    """
    X, T = [], []

    # Read the CSV file into a pandas DataFrame
    df = pd.read_csv(file)

    # Iterate over the last 100 rows of the DataFrame
    all_data = df[['Open', 'High', 'Low', 'Close']].values[-100:]

    data = []
    for i in range(len(all_data) - K):
        # Collect K rows for X and the K+1 day closing price for T
        x = all_data[i:i + K]
        y = all_data[i + K][-1]  # Closing price of the K+1 day
        X.append(x)
        T.append(y)

    # If augment is True, also add reversed data
    if augment:
        for i in range(len(all_data) - K):
            x = all_data[::-1][i:i + K]
            y = all_data[::-1][i + K][-1]
            X.append(x)
            T.append(y)

    # Convert X and T to torch tensors
    return torch.tensor(np.array(X), dtype=torch.float), torch.tensor(np.array(T), dtype=torch.float)

class StocksRNN(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(StocksRNN, self).__init__()
        self.hidden_size = hidden_size
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        # normalize input
        s1, s2, s3 = x.shape
        x = x.reshape(s1, s2*s3)
        min, max = torch.amin(x, axis=1), torch.amax(x, axis=1)
        x = (x-min[:, np.newaxis]) / (max[:, np.newaxis] - min[:, np.newaxis])
        x = x.reshape(s1, s2, s3)
        # RNN Layer
        out, _ = self.rnn(x)
        # Fully connected layer
        out = self.fc(out[:, -1, :])
        # Denormalize output
        return ((out.reshape(-1) * (max-min)) + min).reshape(-1, 1)

class StocksLSTM(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(StocksLSTM, self).__init__()
        self.hidden_size = hidden_size
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        # normalize input
        s1, s2, s3 = x.shape
        x = x.reshape(s1, s2*s3)
        min, max = torch.amin(x, axis=1), torch.amax(x, axis=1)
        x = (x-min[:, np.newaxis]) / (max[:, np.newaxis] - min[:, np.newaxis])
        x = x.reshape(s1, s2, s3)
        # LSTM Layer
        out, _ = self.lstm(x)
        # Fully connected layer
        out = self.fc(out[:, -1, :])
        # Denormalize output
        return ((out.reshape(-1) * (max-min)) + min).reshape(-1, 1)

def get_mean_squared_error(model, files, K, incrDecr=False):
    """
    Given the model, a set of files, and K value, The function will calculate
    the mean squared error of the dataset.
    """
    error = 0
    total = 0

    for f in files:
        x, t = transform_data(f, K)

        if incrDecr:
            output = model(x).reshape(-1)

            t[np.where(x[:, -1, -1] >= t)] = 0
            t[np.where(x[:, -1, -1] < t)] = 1
            output[np.where(x[:, -1, -1] >= output)] = 0
            output[np.where(x[:, -1, -1] < output)] = 1

        else:
            s1, s2, s3 = x.shape
            x = x.reshape(s1, s2*s3)
            min, max = torch.amin(x, axis=1), torch.amax(x, axis=1)
            x = (x-min[:, np.newaxis]) / (max[:, np.newaxis] - min[:, np.newaxis])
            x = x.reshape(s1, s2, s3)
            t = (t-min) / (max - min)

            output = model(x).reshape(-1)

        error += int(sum((output - t)**2).detach())
        total += output.shape[0]

    return error / total

def train_rnn_network(model, train, valid, num_epochs, batch_size, learning_rate, K, name, augment=False, show_data=True):
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    losses, train_acc, valid_acc = [], [], []
    epochs = []

    iter_x = []
    iter_t = []
    for f in train:
        x, t = transform_data(f, K, augment)
        iter_x.append(x)
        iter_t.append(t)

    train_data_x = torch.concat(iter_x, 0)
    train_data_t = torch.concat(iter_t, 0)

    for epoch in range(num_epochs):

        p = np.random.permutation(train_data_t.shape[0])
        X, T = train_data_x[p], train_data_t[p]

        for i in range(0, int(T.shape[0]), batch_size):
            batch_x = X[i: (i+batch_size)]
            batch_t = T[i: (i+batch_size)]
            pred = model(batch_x)
            loss = criterion(pred, batch_t.reshape(-1, 1))
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        losses.append(float(loss))

        epochs.append(epoch)
        train_acc.append(get_mean_squared_error(model, train, K))
        valid_acc.append(get_mean_squared_error(model, valid, K))
        if (epoch+1) % 10 == 0 and show_data:
            print("Epoch %d; Loss %f; Train Acc %f; Val Acc %f" % (
                epoch+1, loss, train_acc[-1], valid_acc[-1]))

    if show_data:
        plt.title(name + " Training Curve")
        plt.plot(epochs, train_acc, label="Train")
        plt.plot(epochs, valid_acc, label="Validation")
        plt.xlabel("Epoch")
        plt.ylabel("Mean Squared Error")
        plt.legend(loc='best')
        plt.savefig(name.replace(" ", "")+".png")
        plt.show()

modelRNN = StocksRNN(4, 150)
train_rnn_network(modelRNN,
                  training_files,
                  validation_files,
                  num_epochs=200,
                  batch_size=500,
                  learning_rate=1e-5,
                  K=15,
                  name="RNN Model")
print("Test Data Error: ", get_mean_squared_error(modelRNN, test_files, 15))
print("Test Data Increase/Decrease Accuracy: ", get_mean_squared_error(modelRNN, test_files, 15, incrDecr=True))

modelLSTM = StocksLSTM(4, 150)
train_rnn_network(modelLSTM,
                  training_files,
                  validation_files,
                  num_epochs=200,
                  batch_size=500,
                  learning_rate=1e-5,
                  K=15,
                  name="LSTM Model")
print("Test Data Accuracy: ", get_mean_squared_error(modelLSTM, test_files, 15))
print("Test Data Increase/Decrease Accuracy: ", get_mean_squared_error(modelLSTM, test_files, 15, incrDecr=True))

modelRNNAug = StocksRNN(4, 150)
train_rnn_network(modelRNNAug,
                  training_files,
                  validation_files,
                  num_epochs=200,
                  batch_size=500,
                  learning_rate=1e-5,
                  K=15,
                  name="RNN Model Augmented",
                  augment=True)
print("Test Data Accuracy: ", get_mean_squared_error(modelRNNAug, test_files, 15))
print("Test Data Increase/Decrease Accuracy: ", get_mean_squared_error(modelRNNAug, test_files, 15, incrDecr=True))

modelLSTMAug = StocksLSTM(4, 150)
train_rnn_network(modelLSTMAug,
                  training_files,
                  validation_files,
                  num_epochs=200,
                  batch_size=500,
                  learning_rate=1e-5,
                  K=15,
                  name="LSTM Model Augmented",
                  augment=True)
print("Test Data Accuracy: ", get_mean_squared_error(modelLSTMAug, test_files, 15))
print("Test Data Increase/Decrease Accuracy: ", get_mean_squared_error(modelLSTMAug, test_files, 15, incrDecr=True))

def goodBadExample(model, K, test_files=test_files):
    """
    Given a model, K, and test_files dataset, this function will output the
    company with the worst mean squared error and the company with the best
    mean squared error. Display a graph for which it least correctly predicted
    the values and a graph for which it most correctly predicted the values.
    """
    bad_error, bad_file = float("-inf"), ""
    good_error, good_file = float("inf"), ""

    for f in test_files:
        error = get_mean_squared_error(model, [f], K)
        if error > bad_error:
            bad_error = error
            bad_file = f

        if error < good_error:
            good_error = error
            good_file = f

    X, T = transform_data(good_file, K)
    Y = model(X)

    plt.title("Best Model Prediction")
    plt.ylabel("Stock Price ($)")
    plt.xlabel("Days")
    plt.plot(np.arange(len(Y)), Y.detach().numpy(), label="Model Prediction")
    plt.plot(np.arange(len(T)), T, label="Target Value")
    plt.legend()
    plt.savefig("BestModelPrediction.png")
    plt.show()

    print("Best Model Prediction Error: ",
          get_mean_squared_error(model, [good_file], K))

    X, T = transform_data(bad_file, K)
    Y = model(X)

    plt.title("Worst Model Prediction")
    plt.ylabel("Stock Price ($)")
    plt.xlabel("Days")
    plt.plot(np.arange(len(Y)), Y.detach().numpy(), label="Model Prediction")
    plt.plot(np.arange(len(T)), T, label="Target Value")
    plt.legend()
    plt.savefig("WorstModelPrediction.png")
    plt.show()

    print("Worst Model Prediction Error: ",
          get_mean_squared_error(model, [bad_file], K))

goodBadExample(modelRNN, 15, test_files=test_files)

def qualitativeResults(model, K, modelName, test_files=test_files):
    """
    Given a model, K, modelname, and a set of test files it will output a graph
    with 9 companies and how the model performed compared to the actual values.
    """
    plt.figure(figsize=(8,6), dpi=100)
    for i in range(9):
        plt.subplot(3, 3, i+1)
        X, T = transform_data(test_files[i], K)
        Y = model(X)
        name = test_files[i].split("/")[-1][:-7]
        plt.title(name)
        plt.plot(np.arange(len(Y)), Y.detach().numpy(), label="Model Prediction")
        plt.plot(np.arange(len(T)), T, label="Target Value")
        plt.xticks([])
        plt.yticks([])

    plt.suptitle(modelName+": Nine Sample Companies")
    plt.subplot(3, 3, 3)
    plt.legend(loc=(0, 1.2))
    plt.savefig(modelName+"NineSampleCompanies.png")
    plt.show()

qualitativeResults(modelRNN, 15, "RNN")

qualitativeResults(modelLSTM, 15, "LSTM")

def testModels(modelType):
    """
    Tests a RNN or LSTM model with the epochs, 50, 100, 200 and batch sizes of
    500, 1000 and previous days of 5, 10, 15 and displays them in table.
    """
    print(modelType, "Model")
    print("Epochs\tBatch Size\tNum Days\tTraining Error\tValidation Error\tTest Error\tClassification Error")
    for epochs in [50, 100, 200]:
        for batch_size in [500, 1000]:
            for K in [5, 10, 15]:
                print(str(epochs) + "\t" + str(batch_size) + "\t\t" + str(K) + "\t\t", end="")
                if modelType == "RNN":
                    model = StocksRNN(4, 150)
                else:
                    model = StocksLSTM(4, 150)
                train_rnn_network(model,
                                  training_files,
                                  validation_files,
                                  num_epochs=epochs,
                                  batch_size=batch_size,
                                  learning_rate=1e-5,
                                  K=K,
                                  name=modelType,
                                  show_data=False)
                train_acc = get_mean_squared_error(model, training_files, K)
                valid_acc = get_mean_squared_error(model, validation_files, K)
                test_acc = get_mean_squared_error(model, test_files, K)
                testc_acc = get_mean_squared_error(model, test_files, K, incrDecr=True)
                print(f'{train_acc:.6f}' + "\t", end="")
                print(f'{valid_acc:.6f}' + "\t\t", end="")
                print(f'{test_acc:.6f}' + "\t", end="")
                print(f'{testc_acc:.6f}' + "\t")

testModels("LSTM")

testModels("RNN")